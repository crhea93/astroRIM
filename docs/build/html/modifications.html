
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Files to Modify &#8212; astroRIM  documentation</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">astroRIM  documentation</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent" role="heading">
 <span class="caption-text">
  Python Files:
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="rim_sequence.html">
   RIM Sequence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rim_model.html">
   RIM Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rim_physical.html">
   RIM Physical
  </a>
 </li>
</ul>
<p class="caption collapsible-parent" role="heading">
 <span class="caption-text">
  Example Modules:
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Notebooks/RIM-Test-1D-Gaussians.html">
   1D Gaussian
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Notebooks/RIM-Test-2D-Gaussians.html">
   2D Gaussians
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Notebooks/RIM-Deconvolving-Spectra.html">
   Deconvolving Real Spectra
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/modifications.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rim-model-py">
   <cite>
    rim_model.py
   </cite>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#init">
     <cite>
      __init__
     </cite>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#call">
     <cite>
      call
     </cite>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rim-physical">
   <cite>
    RIM_physical
   </cite>
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section id="files-to-modify">
<h1>Files to Modify<a class="headerlink" href="#files-to-modify" title="Permalink to this heading">¶</a></h1>
<p>On this page, you will find a description of the two files that users can modify to change the RIM’s architecture or likelihood function.</p>
<section id="rim-model-py">
<h2><cite>rim_model.py</cite><a class="headerlink" href="#rim-model-py" title="Permalink to this heading">¶</a></h2>
<p>The <cite>rim_model.py</cite> file contains the definition of the RIM architecture. Regardless of the dimensions of your RIM, you will need to modify two functions
within the <cite>RIM_model</cite> class: the <cite>__init__</cite> and the <cite>call</cite>.</p>
<section id="init">
<h3><cite>__init__</cite><a class="headerlink" href="#init" title="Permalink to this heading">¶</a></h3>
<p>The default functionality is the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conv_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">rnn_units</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initiation of class</span>

<span class="sd">    Args:</span>
<span class="sd">        conv_filters: Number of convolutional layers (Int)</span>
<span class="sd">        kernel_size: Size of convoluitional kernel (Int)</span>
<span class="sd">        rnn_units: List of units in GRUs ([Int])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="c1"># Define Layers of RIM</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">conv_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                           <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gru1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">rnn_units</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">recurrent_activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span>
                                    <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1DTranspose</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">conv_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gru2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">rnn_units</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">recurrent_activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span>
                                    <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                    <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_units</span> <span class="o">=</span> <span class="n">rnn_units</span>  <span class="c1"># DO NOT CHANGE THIS LINE</span>
</pre></div>
</div>
<p>Here is where we define the architecture of our network. In this example, we have 3 convolutional layers punctuated by gated recurrent units (GRUs).
We can see that the convolutional layers all have the same number of filters and kernel size (this could be changed if you wish). Additionally, each layer
has a stride of 1 with the same padding and a tanh activation function. The GRUs have a tanh activation function and a sigmoid recurrent function. The important
piece here is that we read in a vector describing the number of units for each GRU.</p>
<p>Users can modify any of the defined values above. Additionally, they can add (or delete) layers.</p>
<p>In order to make sure that the network operates in the correct sequence, we must update the <cite>call</cite> function.</p>
</section>
<section id="call">
<h3><cite>call</cite><a class="headerlink" href="#call" title="Permalink to this heading">¶</a></h3>
<p>The <cite>call</cite> function currently ressembles the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sol</span><span class="p">,</span> <span class="n">log_L</span><span class="p">,</span> <span class="n">hidden_states</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A single run through the recurrent inference machine. This is the standard architecture.</span>


<span class="sd">    conv2d -&gt; gru -&gt; conv2d_T -&gt; gru -&gt; conv2d</span>


<span class="sd">    When we go from a convolutional layer to a GRU, we need to first flatten the activation map. We then use the</span>
<span class="sd">    expand_dims function to make sure the input of the GRU has the correct format (batch length, feature dims, 1).</span>

<span class="sd">    Args:</span>

<span class="sd">        sol: Solution at time step t (x_t)</span>
<span class="sd">        log_L: Gradient of log likelihood</span>
<span class="sd">        hidden_states: List of hidden state vectors</span>
<span class="sd">        return_state: Return the hidden state boolean</span>
<span class="sd">        training: Boolean determining whether or not the layer acts in training or inference mode</span>

<span class="sd">    Return:</span>
<span class="sd">        x: Value of delta x</span>
<span class="sd">        states1: State vector one (optional)</span>
<span class="sd">        states2: State vector two (optional)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">[</span><span class="n">states1</span><span class="p">,</span> <span class="n">states2</span><span class="p">]</span> <span class="o">=</span> <span class="n">hidden_states</span>
    <span class="n">sol</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">sol</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Don&#39;t change</span>
    <span class="n">log_L</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">log_L</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Don&#39;t change</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">sol</span><span class="p">,</span> <span class="n">log_L</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Pass previous solution and gradient of log likelihood at previous step; don&#39;t change</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">states1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">states1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru1</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">states1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">states1</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">states2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">states2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru2</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">states2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">states2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1d_3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Don&#39;t change</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">states1</span><span class="p">,</span> <span class="n">states2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">return_state</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden_states</span>
    <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>It is here that you would change the structure depending on whatever architecture you wish to employ.</p>
</section>
</section>
<section id="rim-physical">
<h2><cite>RIM_physical</cite><a class="headerlink" href="#rim-physical" title="Permalink to this heading">¶</a></h2>
<p>In this function we define the gradient of the log likelihood. The standard implementation is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_grad_standard</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">C_N</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculate gradient of log likelihood function</span>

<span class="sd">Args:</span>
<span class="sd">    Y: True &quot;unconvolved&quot; model</span>
<span class="sd">    A: Convolution matrix</span>
<span class="sd">    C_N: Noise vector (1D)</span>
<span class="sd">    x: Current solution calculated from RIM</span>

<span class="sd">Return:</span>
<span class="sd">    asinh of the gradient</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">C_N</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C_N</span><span class="p">)</span>  <span class="c1"># Diagonalize the noise vector</span>
<span class="n">C_N</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">C_N</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Calculate maximum value of x</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">x_max</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>  <span class="c1"># Make sure no weird division</span>
<span class="n">x_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>   <span class="c1"># Normalize x -- we do this to get the correct normalization so that A*x is correctly scaled</span>
<span class="n">conv_sol</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bij,bk-&gt;bi&#39;</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">x_norm</span><span class="p">)</span>  <span class="c1"># Calculate A*x</span>
<span class="n">C_N_inv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">C_N</span><span class="p">)</span>  <span class="c1"># Invert C_N</span>
<span class="n">residual_init</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">conv_sol</span>  <span class="c1"># Returns a bn vector</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...i, ...ij -&gt; ...j&quot;</span><span class="p">,</span> <span class="n">residual_init</span><span class="p">,</span> <span class="n">C_N_inv</span><span class="p">)</span>  <span class="c1"># Multiply (Y - conv_sol).T*C_N_inv -&gt; returns a bn vector</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...i, ...ij -&gt; ...j&quot;</span><span class="p">,</span> <span class="n">residual</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>  <span class="c1"># Multiply residual by A</span>

<span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">asinh</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Carter Rhea & Alexandre Adam<br/>
        
            &copy; Copyright 2022, Carter Rhea &amp; Alexandre Adam.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>